{"ast":null,"code":"/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n */\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { subtokenize } from 'micromark-util-subtokenize';\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\n\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n};\n/** @type {Construct} */\n\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n};\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\n\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token} */\n  let previous;\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    effects.enter('content');\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    });\n    return data(code);\n  }\n  /** @type {State} */\n\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code);\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    } // Data.\n\n\n    effects.consume(code);\n    return data;\n  }\n  /** @type {State} */\n\n\n  function contentEnd(code) {\n    effects.exit('chunkContent');\n    effects.exit('content');\n    return ok(code);\n  }\n  /** @type {State} */\n\n\n  function contentContinue(code) {\n    effects.consume(code);\n    effects.exit('chunkContent');\n    previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous\n    });\n    previous = previous.next;\n    return data;\n  }\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this;\n  return startLookahead;\n  /** @type {State} */\n\n  function startLookahead(code) {\n    effects.exit('chunkContent');\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return factorySpace(effects, prefixed, 'linePrefix');\n  }\n  /** @type {State} */\n\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code);\n    }\n\n    const tail = self.events[self.events.length - 1];\n\n    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === 'linePrefix' && tail[2].sliceSerialize(tail[1], true).length >= 4) {\n      return ok(code);\n    }\n\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n  }\n}","map":{"version":3,"sources":["/Users/dragos/Ruby-developer/GitHubDev/muse-ant-design-dashboard/node_modules/micromark-core-commonmark/lib/content.js"],"names":["factorySpace","markdownLineEnding","subtokenize","content","tokenize","tokenizeContent","resolve","resolveContent","continuationConstruct","tokenizeContinuation","partial","events","effects","ok","previous","start","code","enter","contentType","data","contentEnd","check","contentContinue","consume","exit","next","nok","self","startLookahead","prefixed","tail","length","parser","constructs","disable","null","includes","type","sliceSerialize","interrupt","flow"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAQA,YAAR,QAA2B,yBAA3B;AACA,SAAQC,kBAAR,QAAiC,0BAAjC;AACA,SAAQC,WAAR,QAA0B,4BAA1B;AAEA;AACA;AACA;AACA;;AACA,OAAO,MAAMC,OAAO,GAAG;AACrBC,EAAAA,QAAQ,EAAEC,eADW;AAErBC,EAAAA,OAAO,EAAEC;AAFY,CAAhB;AAIP;;AAEA,MAAMC,qBAAqB,GAAG;AAC5BJ,EAAAA,QAAQ,EAAEK,oBADkB;AAE5BC,EAAAA,OAAO,EAAE;AAFmB,CAA9B;AAIA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAASH,cAAT,CAAwBI,MAAxB,EAAgC;AAC9BT,EAAAA,WAAW,CAACS,MAAD,CAAX;AACA,SAAOA,MAAP;AACD;AACD;;;AAEA,SAASN,eAAT,CAAyBO,OAAzB,EAAkCC,EAAlC,EAAsC;AACpC;AACA,MAAIC,QAAJ;AACA,SAAOC,KAAP;AACA;;AAEA,WAASA,KAAT,CAAeC,IAAf,EAAqB;AACnBJ,IAAAA,OAAO,CAACK,KAAR,CAAc,SAAd;AACAH,IAAAA,QAAQ,GAAGF,OAAO,CAACK,KAAR,CAAc,cAAd,EAA8B;AACvCC,MAAAA,WAAW,EAAE;AAD0B,KAA9B,CAAX;AAGA,WAAOC,IAAI,CAACH,IAAD,CAAX;AACD;AACD;;;AAEA,WAASG,IAAT,CAAcH,IAAd,EAAoB;AAClB,QAAIA,IAAI,KAAK,IAAb,EAAmB;AACjB,aAAOI,UAAU,CAACJ,IAAD,CAAjB;AACD;;AAED,QAAIf,kBAAkB,CAACe,IAAD,CAAtB,EAA8B;AAC5B,aAAOJ,OAAO,CAACS,KAAR,CACLb,qBADK,EAELc,eAFK,EAGLF,UAHK,EAILJ,IAJK,CAAP;AAKD,KAXiB,CAWhB;;;AAEFJ,IAAAA,OAAO,CAACW,OAAR,CAAgBP,IAAhB;AACA,WAAOG,IAAP;AACD;AACD;;;AAEA,WAASC,UAAT,CAAoBJ,IAApB,EAA0B;AACxBJ,IAAAA,OAAO,CAACY,IAAR,CAAa,cAAb;AACAZ,IAAAA,OAAO,CAACY,IAAR,CAAa,SAAb;AACA,WAAOX,EAAE,CAACG,IAAD,CAAT;AACD;AACD;;;AAEA,WAASM,eAAT,CAAyBN,IAAzB,EAA+B;AAC7BJ,IAAAA,OAAO,CAACW,OAAR,CAAgBP,IAAhB;AACAJ,IAAAA,OAAO,CAACY,IAAR,CAAa,cAAb;AACAV,IAAAA,QAAQ,CAACW,IAAT,GAAgBb,OAAO,CAACK,KAAR,CAAc,cAAd,EAA8B;AAC5CC,MAAAA,WAAW,EAAE,SAD+B;AAE5CJ,MAAAA;AAF4C,KAA9B,CAAhB;AAIAA,IAAAA,QAAQ,GAAGA,QAAQ,CAACW,IAApB;AACA,WAAON,IAAP;AACD;AACF;AACD;;;AAEA,SAASV,oBAAT,CAA8BG,OAA9B,EAAuCC,EAAvC,EAA2Ca,GAA3C,EAAgD;AAC9C,QAAMC,IAAI,GAAG,IAAb;AACA,SAAOC,cAAP;AACA;;AAEA,WAASA,cAAT,CAAwBZ,IAAxB,EAA8B;AAC5BJ,IAAAA,OAAO,CAACY,IAAR,CAAa,cAAb;AACAZ,IAAAA,OAAO,CAACK,KAAR,CAAc,YAAd;AACAL,IAAAA,OAAO,CAACW,OAAR,CAAgBP,IAAhB;AACAJ,IAAAA,OAAO,CAACY,IAAR,CAAa,YAAb;AACA,WAAOxB,YAAY,CAACY,OAAD,EAAUiB,QAAV,EAAoB,YAApB,CAAnB;AACD;AACD;;;AAEA,WAASA,QAAT,CAAkBb,IAAlB,EAAwB;AACtB,QAAIA,IAAI,KAAK,IAAT,IAAiBf,kBAAkB,CAACe,IAAD,CAAvC,EAA+C;AAC7C,aAAOU,GAAG,CAACV,IAAD,CAAV;AACD;;AAED,UAAMc,IAAI,GAAGH,IAAI,CAAChB,MAAL,CAAYgB,IAAI,CAAChB,MAAL,CAAYoB,MAAZ,GAAqB,CAAjC,CAAb;;AAEA,QACE,CAACJ,IAAI,CAACK,MAAL,CAAYC,UAAZ,CAAuBC,OAAvB,CAA+BC,IAA/B,CAAoCC,QAApC,CAA6C,cAA7C,CAAD,IACAN,IADA,IAEAA,IAAI,CAAC,CAAD,CAAJ,CAAQO,IAAR,KAAiB,YAFjB,IAGAP,IAAI,CAAC,CAAD,CAAJ,CAAQQ,cAAR,CAAuBR,IAAI,CAAC,CAAD,CAA3B,EAAgC,IAAhC,EAAsCC,MAAtC,IAAgD,CAJlD,EAKE;AACA,aAAOlB,EAAE,CAACG,IAAD,CAAT;AACD;;AAED,WAAOJ,OAAO,CAAC2B,SAAR,CAAkBZ,IAAI,CAACK,MAAL,CAAYC,UAAZ,CAAuBO,IAAzC,EAA+Cd,GAA/C,EAAoDb,EAApD,EAAwDG,IAAxD,CAAP;AACD;AACF","sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n */\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {subtokenize} from 'micromark-util-subtokenize'\n\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n}\n/** @type {Construct} */\n\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n}\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\n\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token} */\n  let previous\n  return start\n  /** @type {State} */\n\n  function start(code) {\n    effects.enter('content')\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    })\n    return data(code)\n  }\n  /** @type {State} */\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        continuationConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    } // Data.\n\n    effects.consume(code)\n    return data\n  }\n  /** @type {State} */\n\n  function contentEnd(code) {\n    effects.exit('chunkContent')\n    effects.exit('content')\n    return ok(code)\n  }\n  /** @type {State} */\n\n  function contentContinue(code) {\n    effects.consume(code)\n    effects.exit('chunkContent')\n    previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous\n    })\n    previous = previous.next\n    return data\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this\n  return startLookahead\n  /** @type {State} */\n\n  function startLookahead(code) {\n    effects.exit('chunkContent')\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, prefixed, 'linePrefix')\n  }\n  /** @type {State} */\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    const tail = self.events[self.events.length - 1]\n\n    if (\n      !self.parser.constructs.disable.null.includes('codeIndented') &&\n      tail &&\n      tail[1].type === 'linePrefix' &&\n      tail[2].sliceSerialize(tail[1], true).length >= 4\n    ) {\n      return ok(code)\n    }\n\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n  }\n}\n"]},"metadata":{},"sourceType":"module"}